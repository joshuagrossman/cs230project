{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# TODO: fold in golden pianoroll for train (1 pixel wide) and test (many pixels (5ish seconds) wide)\n",
    "\n",
    "\"\"\"\n",
    "Directories\n",
    "\"\"\"\n",
    "HOME = os.path.expanduser(\"~\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "#WTC1_WAV_DIR = \"/WTC1-WAV\"\n",
    "#WTC2_WAV_DIR = \"/WTC2-WAV\"\n",
    "\n",
    "WTC1_MIDI_DIR = \"/WTC1-MIDI\"\n",
    "WTC2_MIDI_DIR = \"/WTC2-MIDI\"\n",
    "\n",
    "# CQT heatmap slices for CNN training\n",
    "TRAIN_CQT_CNN_SLICES_IN_DIR = \"Train-CQT-CNN-Slices-In\"\n",
    "\n",
    "# Time series text data for full-WAV CQT\n",
    "TRAIN_TIME_SERIES_IN_DIR = \"Train-Time-Series-In\"\n",
    "\n",
    "# CNN output on training data, if needed\n",
    "TRAIN_PIANOROLL_OUT_DIR = \"Train-Pianoroll-Out\"\n",
    "\n",
    "# CNN output on test data\n",
    "TEST_PIANOROLL_OUT_DIR = \"Test-Pianoroll-Out\"\n",
    "\n",
    "# What the CNN output is supposed to be\n",
    "TEST_PIANOROLL_GOLDEN_DIR = \"Test-Pianoroll-Golden\"\n",
    "\n",
    "# CNN output, converted to MIDI for human listening\n",
    "TEST_MIDI_OUT_DIR = \"Test-MIDI-Out\"\n",
    "\n",
    "# CQT heatmap slices for CNN\n",
    "TEST_CQT_CNN_SLICES_IN_DIR = \"Test-CQT-CNN-Slices-In\"\n",
    "\n",
    "# Time series text data for full-WAV CQT\n",
    "TEST_TIME_SERIES_IN_DIR = \"Test-Time-Series-In\"\n",
    "\n",
    "MODEL_CKPT_DIR = \"Models\"\n",
    "\n",
    "# corresponds to a max song length of 3 hours\n",
    "MAX_START_MS_DIGITS = 7\n",
    "\n",
    "# \"\"\"\n",
    "# File name templates\n",
    "# \"\"\"\n",
    "# FUGUE_WAV_NAME_TEMPLATE = \"(Fugue_No\\._%s)[_\\.].+\"\n",
    "# PRELUDE_WAV_NAME_TEMPLATE = \"(Prelude_No\\._%s)[_\\.].+\"\n",
    "\n",
    "# # E.g., Fugue_No._1_Slice_458.png (which means 458 milliseconds in)\n",
    "# CQT_SLICE_NAME_TEMPLATE = \"%s_Slice_(%s).csv\"\n",
    "\n",
    "# # E.g., Fugue_No._1_Pianoroll_6.png\n",
    "# PIANOROLL_NAME_TEMPLATE = \"%s_Pianoroll_(%s).csv\"\n",
    "\n",
    "# # E.g., Fugue_No._1.mid\n",
    "# MIDI_OUT_NAME_TEMPLATE = \"%s.mid\"\n",
    "\n",
    "# RESULTS_PATH = \"/numericalResults%s.txt\"\n",
    "\n",
    "\"\"\"\n",
    "Numerical file parameters\n",
    "\"\"\"\n",
    "CQT_SNAPSHOT_WIDTH_IN_SECONDS = 5\n",
    "CQT_SNAPSHOT_WIDTH_IN_PIXELS = 1000 # TODO: is it too high? We should have about one solid colored block per pixel\n",
    "CQT_SNAPSHOT_HEIGHT_IN_PIXELS = 1000\n",
    "\n",
    "CQT_SAMPLING_RATE = 344.53125 # (which is 44100 / 128)\n",
    "\n",
    "CQT_SLICE_RADIUS_IN_PIXELS = 2\n",
    "CQT_SLICE_OFFSET_IN_PIXELS = 3\n",
    "CQT_SLICE_WIDTH_IN_PIXELS = 1 + 2 * CQT_SLICE_RADIUS_IN_PIXELS\n",
    "\n",
    "CQT_SLICE_HEIGHT_IN_PIXELS = CQT_SNAPSHOT_HEIGHT_IN_PIXELS\n",
    "\n",
    "# TRAIN_PIANOROLL_WIDTH_IN_PIXELS = 1\n",
    "# TEST_PIANOROLL_WIDTH_IN_SECONDS = 5\n",
    "# TEST_PIANOROLL_WIDTH_IN_PIXELS = float(TEST_PIANOROLL_WIDTH_IN_SECONDS) * TRAIN_PIANOROLL_WIDTH_IN_PIXELS / CQT_SLICE_WIDTH_IN_PIXELS * CQT_SNAPSHOT_WIDTH_IN_PIXELS / CQT_SNAPSHOT_WIDTH_IN_SECONDS\n",
    "\n",
    "\"\"\"\n",
    "Hyperparameters\n",
    "\"\"\"\n",
    "#CONTEXT_WINDOW_ROWS = 352\n",
    "CONTEXT_WINDOW_ROWS = 288\n",
    "CONTEXT_WINDOW_COLS = 5\n",
    "NUM_RGB_CHANNELS = 1\n",
    "\n",
    "NUM_KEYS = 88\n",
    "DROPOUT_P = 0.25\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "SEQUENCE_LENGTH_IN_SLICES = 50 # (~5 seconds)\n",
    "SEQUENCE_SAMPLE_FREQ_IN_SLICES = 175\n",
    "\n",
    "NUM_PIECES_TO_TEST = 4\n",
    "TEST_SPLIT = 0.25\n",
    "VALIDATION_SPLIT = 0.333\n",
    "\n",
    "# CHECKPOINT_EPOCH = 80\n",
    "# CHECKPOINT_VAL_LOSS = 0.49\n",
    "\n",
    "CHECKPOINT_EPOCH = 100\n",
    "CHECKPOINT_VAL_LOSS = 0.17\n",
    "\n",
    "BINS_PER_OCTAVE = 36\n",
    "FILTER_SCALE = 0.5\n",
    "HOP_LENGTH = 128\n",
    "\n",
    "\"\"\"\n",
    "File conversion parameters\n",
    "\"\"\"\n",
    "NOISE_PARAMETER = 0.01\n",
    "DEFAULT_SOUND_FONT = '~/.fluidsynth/default_sound_font.sf2'\n",
    "SAMPLE_RATE_IN_HZ = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "import csv\n",
    "import pdb\n",
    "import argparse\n",
    "import threading\n",
    "import time\n",
    "import math\n",
    "import h5py\n",
    "import librosa, librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "def get_data(piece):\n",
    "    hf = h5py.File(piece, \"r\")\n",
    "    slices = np.array(hf.get(\"slice_indices\"))\n",
    "    cqt = np.array(hf.get(\"cqt\"))\n",
    "    pianoroll = np.array(hf.get(\"pianoroll\"))\n",
    "    slice_index = 0\n",
    "\n",
    "    return slices, cqt, pianoroll, slice_index\n",
    "\n",
    "\n",
    "@threadsafe_generator\n",
    "def generator(pieces, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Yield one batch at a time of inputs to the CNN.\n",
    "    \"\"\"\n",
    "    piece_index = 0\n",
    "    piece_slices, piece_cqt, piece_pianoroll, slice_index = get_data(pieces[piece_index])\n",
    "\n",
    "    while True:\n",
    "        # In this iteration of the loop, yield a single batch of sequences\n",
    "        batch_X = np.zeros((batch_size, SEQUENCE_LENGTH_IN_SLICES, CONTEXT_WINDOW_ROWS, CONTEXT_WINDOW_COLS, 1))\n",
    "        batch_Y = np.zeros((batch_size, SEQUENCE_LENGTH_IN_SLICES, NUM_KEYS))\n",
    "        reached_end_of_dataset = False\n",
    "        for batch_sequence_index in range(batch_size):\n",
    "            if slice_index + SEQUENCE_LENGTH_IN_SLICES > piece_slices.shape[0]:\n",
    "                # We can't make another full sequence with this piece\n",
    "                if piece_index + 1 >= len(pieces):\n",
    "                    # We've reached the end of an epoch--don't yield these incomplete batches\n",
    "                    reached_end_of_dataset = True\n",
    "                    break\n",
    "\n",
    "                # Skipping to the next piece\n",
    "                piece_index += 1\n",
    "                piece_slices, piece_cqt, piece_pianoroll, slice_index = get_data(pieces[piece_index])\n",
    "\n",
    "            # Continue constructing the batch by constructing a sequence and adding it to the batch\n",
    "            sequence_slices = piece_slices[slice_index:(slice_index + SEQUENCE_LENGTH_IN_SLICES)]\n",
    "            sequence_cqt = np.zeros((SEQUENCE_LENGTH_IN_SLICES, CONTEXT_WINDOW_ROWS, CONTEXT_WINDOW_COLS))\n",
    "            sequence_pianoroll = np.zeros((SEQUENCE_LENGTH_IN_SLICES, NUM_KEYS))\n",
    "            for sequence_index, slice in enumerate(sequence_slices):\n",
    "                [start, end] = slice\n",
    "                sequence_cqt[sequence_index, :, :] = piece_cqt[:, start:end]\n",
    "                sequence_pianoroll[sequence_index, :] = np.max(piece_pianoroll[:, start:end], axis=1)\n",
    "\n",
    "            # Add new sequence to the batches\n",
    "            batch_X[batch_sequence_index, :, :, :, 0] = sequence_cqt\n",
    "            batch_Y[batch_sequence_index, :, :] = sequence_pianoroll\n",
    "\n",
    "            # Increment slice index and go to the next sequence\n",
    "            slice_index += SEQUENCE_SAMPLE_FREQ_IN_SLICES\n",
    "\n",
    "        # Batch is done being constructed, yield to CNN\n",
    "        if reached_end_of_dataset:\n",
    "            # We weren't able to fill out this batch, just reset everything and let the while-loop restart\n",
    "            piece_index = 0\n",
    "            piece_slices, piece_cqt, piece_pianoroll, slice_index = get_data(pieces[piece_index])\n",
    "        else:\n",
    "#             pdb.set_trace()\n",
    "            librosa.display.specshow(batch_X[0, 35, :, :, 0], x_axis='time', y_axis='chroma', hop_length=64)\n",
    "            print(batch_Y[0, 35])\n",
    "            return\n",
    "            yield batch_X, batch_Y\n",
    "\n",
    "\n",
    "def num_samples(dataset):\n",
    "    \"\"\"\n",
    "    Find the number of sequences given by the dataset.\n",
    "    \"\"\"\n",
    "    total_num_sequences = 0\n",
    "    for piece in dataset:\n",
    "        hf = h5py.File(piece, \"r\")\n",
    "        num_slices = np.array(hf.get(\"slice_indices\")).shape[0]\n",
    "        num_sequences = (num_slices + SEQUENCE_SAMPLE_FREQ_IN_SLICES - SEQUENCE_LENGTH_IN_SLICES) \\\n",
    "            // SEQUENCE_SAMPLE_FREQ_IN_SLICES # trim so that there's a whole number of sequences\n",
    "        total_num_sequences += num_sequences\n",
    "\n",
    "    return total_num_sequences\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"\n",
    "    Specifies a simple CNN/LSTM recurrent neural network.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    conv = Conv2D(filters=20,\n",
    "                 kernel_size=(20, 2),\n",
    "                 strides=(1, 1),\n",
    "                 padding='SAME',\n",
    "                 activation='relu')\n",
    "    model.add(TimeDistributed(conv, input_shape=(SEQUENCE_LENGTH_IN_SLICES, CONTEXT_WINDOW_ROWS, CONTEXT_WINDOW_COLS, 1)))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(4, 2), strides=(2, 1))))\n",
    "    model.add(TimeDistributed(Conv2D(20, kernel_size=(20, 2), strides=(10, 1), activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(4, 2), strides=(2, 1))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(TimeDistributed(Dense(500)))\n",
    "    model.add(LSTM(500, input_shape=(SEQUENCE_LENGTH_IN_SLICES, 500), return_sequences=True))\n",
    "    model.add(LSTM(200, input_shape=(SEQUENCE_LENGTH_IN_SLICES, 500), return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(88, activation = \"sigmoid\")))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(pieces):\n",
    "    \"\"\"\n",
    "    Trains CNN and evaluates it on test set. Checkpoints are saved in a directory.\n",
    "\n",
    "    Inspired by https://github.com/chaumifan/DSL_Final\n",
    "    \"\"\"\n",
    "\n",
    "    print('Creating CNN model\\n')\n",
    "    model = create_model()\n",
    "    print('Compiling CNN model\\n')\n",
    "    opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    history = AccuracyHistory()\n",
    "    checkpoint_path = os.path.join(MODEL_CKPT_DIR, 'ckpt.h5')\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path + 'weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=1, save_best_only=False, mode='auto', period=10)\n",
    "    \n",
    "    boundary = math.floor((1.0 - VALIDATION_SPLIT) * len(pieces))\n",
    "    train_pieces = pieces[:boundary]\n",
    "    valid_pieces = pieces[boundary:]\n",
    "\n",
    "    num_train_samples = num_samples(train_pieces)\n",
    "    num_valid_samples = num_samples(valid_pieces)\n",
    "\n",
    "    print(\"Number of ~5s training sequences:\", num_train_samples)\n",
    "    print(\"Number of ~5s validation sequences:\", num_valid_samples)\n",
    "\n",
    "    model.fit_generator(generator=generator(train_pieces),\n",
    "                        steps_per_epoch=num_train_samples // BATCH_SIZE,\n",
    "                        validation_data=generator(valid_pieces),\n",
    "                        validation_steps=num_valid_samples // BATCH_SIZE,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        verbose=1,\n",
    "                        callbacks=[history, checkpoint])\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def evaluate_model(x_test, y_test, model, history):\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    print('Train loss: ', score[0])\n",
    "    print('Train accuracy: ', score[1])\n",
    "\n",
    "    print(history.acc)\n",
    "\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), history.acc)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig('test_loss.png')\n",
    "\n",
    "    \n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback for keeping record of training accuracy.\n",
    "\n",
    "    From http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "\n",
    "def restore_model(epoch, val_loss):\n",
    "    checkpoint_path = \"Models/\"    \n",
    "    model = create_model()\n",
    "    file = checkpoint_path + 'ckpt.h5weights.%d-%.2f.hdf5' % (epoch, val_loss)\n",
    "    model.load_weights(file)\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_predictions(cqt_data, midiFilename):\n",
    "    \"\"\"\n",
    "    Given a set of cqt_slice_paths, runs predict on each slice and adds CNN\n",
    "    output as a column to pianoroll prediction. Writes pianoroll prediction to file.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = restore_model(CHECKPOINT_EPOCH, CHECKPOINT_VAL_LOSS)\n",
    "    print(\"CNN model restored.\")\n",
    "    cqt_array = np.array(cqt_data)\n",
    "\n",
    "    predictions = None\n",
    "    for i in range(cqt_array.shape[1]):\n",
    "        small_slice = cqt_array[:,i]\n",
    "        repeated_slice = np.asarray([[row] * 9 for row in small_slice])\n",
    "        cqt_slice = np.expand_dims(repeated_slice, 3)\n",
    "        cqt_slice = np.expand_dims(cqt_slice, 0)\n",
    "        pred = model.predict(cqt_slice)\n",
    "        bool_array = pred >= 0.5\n",
    "        result = bool_array.astype(int)\n",
    "        if predictions is None:\n",
    "            predictions = result.T\n",
    "        else:\n",
    "            predictions = np.hstack((predictions, result.T))\n",
    "    print(\"Pianoroll predictions made.\")\n",
    "\n",
    "    outPianorollPath = os.path.join(TEST_PIANOROLL_OUT_DIR, midiFilename).replace(\"\\\\\", \"/\")\n",
    "    np.savetxt(outPianorollPath, predictions, fmt='%i', delimiter='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CNN model\n",
      "\n",
      "Compiling CNN model\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_8 (TimeDist (None, 50, 288, 5, 20)    820       \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 50, 143, 4, 20)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 50, 13, 3, 20)     16020     \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 50, 5, 2, 20)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 50, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 50, 500)           100500    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50, 500)           2002000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50, 200)           560800    \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 50, 88)            17688     \n",
      "=================================================================\n",
      "Total params: 2,697,828\n",
      "Trainable params: 2,697,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Number of ~5s training sequences: 380\n",
      "Number of ~5s validation sequences: 190\n",
      "Epoch 1/10\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-945315ff6104>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest_pieces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpiece_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mboundary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pieces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-9984a6539168>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(pieces)\u001b[0m\n\u001b[0;32m    167\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                         callbacks=[history, checkpoint])\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "piece_paths = [os.path.join(\"C:\\\\Users\\\\aitan\\\\Documents\\\\cs230project\\\\sample-h5\", h5_file) \\\n",
    "    for h5_file in os.listdir(\"C:\\\\Users\\\\aitan\\\\Documents\\\\cs230project\\\\sample-h5\") if \"Chamber\" not in h5_file]\n",
    "\n",
    "# Split pieces into train/test\n",
    "boundary = math.floor((1.0 - TEST_SPLIT) * len(piece_paths))\n",
    "train_pieces = piece_paths[:boundary]\n",
    "test_pieces = piece_paths[boundary:]\n",
    "\n",
    "model, history = train_model(train_pieces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
